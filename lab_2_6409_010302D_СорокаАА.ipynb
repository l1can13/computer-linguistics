{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2\n",
    "\n",
    "**Требования:**\n",
    "* Python >= 3.X\n",
    "\n",
    "Лабораторную работу необходимо выполнять в данном шаблоне. Результатом работы будет являться файл (с измененным именем), который необходимо выложить в Moodle.\n",
    "\n",
    "**Важно!!!** Имя файлу задавайте по следующему шаблону **lab_2_Группа_ФамилияИО.ipynb**. Например: если Вас зовут Иванов Иван Иванович, и Вы обучаетесь в группе 6207_010302D, то имя файла будет выглядеть так **lab_2_6407_010302D_ИвановИИ.ipynb**.\n",
    "\n",
    "Необходимо провести исследование различных способов представления документов и их влияние на качество определения тональности.\n",
    "\n",
    "В качестве входных данных к лабораторной работе взят широко известный набор данных IMDB, содержащий 50K обзоров фильмов ([imdb-dataset-of-50k-movie-reviews](https://disk.yandex.ru/i/DDb0zuyUmts5QA)). Откликами являются значения двух классов positive и negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:20:43.884942700Z",
     "start_time": "2024-05-02T20:20:43.504942500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Код загрузки данных\n",
    "# Если хотите добавить какие-либо библиотеки\n",
    "# добавляйте их ИМЕННО ЗДЕСЬ\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "imdb_data = pd.read_csv(r'input/IMDB Dataset.csv')\n",
    "imdb_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг №1 Подготовка данных\n",
    "\n",
    "Обязательно предобработайте данные!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:21:01.879333100Z",
     "start_time": "2024-05-02T20:20:43.886942600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lican\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lican\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              review sentiment\n0  one reviewer mentioned watching oz episode you...  positive\n1  wonderful little production filming technique ...  positive\n2  thought wonderful way spend time hot summer we...  positive\n3  basically there family little boy jake think t...  negative\n4  petter matteis love time money visually stunni...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewer mentioned watching oz episode you...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there family little boy jake think t...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love time money visually stunni...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Установите NLTK ресурсы (только при первом запуске)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Функция для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Удаление HTML тегов\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Удаление специальных символов и чисел\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Токенизация текста\n",
    "    words = text.split()\n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Лемматизация слов\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Соединение слов обратно в строку\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Применение предобработки ко всему набору данных\n",
    "imdb_data['review'] = imdb_data['review'].apply(preprocess_text)\n",
    "imdb_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве исследуемых способов представления текстов необходимо рассмотреть:\n",
    "\n",
    "#### 1.Компоненты вектора: частоты ([CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:21:04.561334100Z",
     "start_time": "2024-05-02T20:21:02.084333700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы частот слов: (50000, 150902)\n",
      "Тип данных матрицы: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Просмотр содержимого матрицы в формате (документ, термин): частота\n",
      "  (0, 94282)\t1\n",
      "  (0, 110774)\t1\n",
      "  (0, 82781)\t1\n",
      "  (0, 144631)\t2\n",
      "  (0, 96735)\t5\n",
      "  (0, 41463)\t2\n",
      "  (0, 149894)\t1\n",
      "  (0, 61367)\t1\n",
      "  (0, 111303)\t2\n",
      "  (0, 42753)\t1\n",
      "  (0, 57464)\t1\n",
      "  (0, 47191)\t2\n",
      "  (0, 133283)\t1\n",
      "  (0, 127651)\t2\n",
      "  (0, 17115)\t1\n",
      "  (0, 139807)\t1\n",
      "  (0, 115221)\t1\n",
      "  (0, 143062)\t4\n",
      "  (0, 118246)\t1\n",
      "  (0, 148008)\t2\n",
      "  (0, 53363)\t2\n",
      "  (0, 137422)\t1\n",
      "  (0, 119993)\t4\n",
      "  (0, 44298)\t1\n",
      "  (0, 58567)\t1\n",
      "  :\t:\n",
      "  (0, 146520)\t2\n",
      "  (0, 123242)\t1\n",
      "  (0, 90335)\t1\n",
      "  (0, 65428)\t2\n",
      "  (0, 71130)\t1\n",
      "  (0, 95083)\t1\n",
      "  (0, 52297)\t2\n",
      "  (0, 145342)\t1\n",
      "  (0, 79887)\t1\n",
      "  (0, 83512)\t1\n",
      "  (0, 23681)\t1\n",
      "  (0, 137791)\t1\n",
      "  (0, 13302)\t1\n",
      "  (0, 72883)\t1\n",
      "  (0, 127386)\t1\n",
      "  (0, 121507)\t1\n",
      "  (0, 43404)\t1\n",
      "  (0, 81320)\t1\n",
      "  (0, 11243)\t1\n",
      "  (0, 25367)\t1\n",
      "  (0, 139172)\t1\n",
      "  (0, 142832)\t1\n",
      "  (0, 135859)\t1\n",
      "  (0, 30797)\t1\n",
      "  (0, 120435)\t1\n"
     ]
    }
   ],
   "source": [
    "# Инициализация CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Векторизация текста\n",
    "X_counts = vectorizer.fit_transform(imdb_data['review'])\n",
    "\n",
    "# Вывод результатов векторизации\n",
    "print(\"Размер матрицы частот слов:\", X_counts.shape)\n",
    "print(\"Тип данных матрицы:\", type(X_counts))\n",
    "print(\"Просмотр содержимого матрицы в формате (документ, термин): частота\")\n",
    "print(X_counts[0])  # Вывод частот для первого документа в наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Компоненты вектора: оценки tf-idf для слова ([TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:21:07.085333900Z",
     "start_time": "2024-05-02T20:21:04.561334100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы TF-IDF: (50000, 150902)\n",
      "Тип данных матрицы: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Просмотр содержимого матрицы в формате (документ, термин): TF-IDF вес\n",
      "  (0, 120435)\t0.04757122457613276\n",
      "  (0, 30797)\t0.07635457258967616\n",
      "  (0, 135859)\t0.05538630507366096\n",
      "  (0, 142832)\t0.1305707580139631\n",
      "  (0, 139172)\t0.07354107464095014\n",
      "  (0, 25367)\t0.07530462963924812\n",
      "  (0, 11243)\t0.046438753026677326\n",
      "  (0, 81320)\t0.038096522346259876\n",
      "  (0, 43404)\t0.047996707643687575\n",
      "  (0, 121507)\t0.060770830794523424\n",
      "  (0, 127386)\t0.05358565572770784\n",
      "  (0, 72883)\t0.046965321075028175\n",
      "  (0, 13302)\t0.08213901875469606\n",
      "  (0, 137791)\t0.051561572140253795\n",
      "  (0, 23681)\t0.05389703531655214\n",
      "  (0, 83512)\t0.053266150286272296\n",
      "  (0, 79887)\t0.09125978188332663\n",
      "  (0, 145342)\t0.026714530645439723\n",
      "  (0, 52297)\t0.04974372271755835\n",
      "  (0, 95083)\t0.05026591237784174\n",
      "  (0, 71130)\t0.046184072375485184\n",
      "  (0, 65428)\t0.1690931491548427\n",
      "  (0, 90335)\t0.10954453998156245\n",
      "  (0, 123242)\t0.0722910362848812\n",
      "  (0, 146520)\t0.19464624975192507\n",
      "  :\t:\n",
      "  (0, 58567)\t0.08185848852601448\n",
      "  (0, 44298)\t0.08490041914517983\n",
      "  (0, 119993)\t0.1264984513474942\n",
      "  (0, 137422)\t0.06395430351062704\n",
      "  (0, 53363)\t0.058962061148162555\n",
      "  (0, 148008)\t0.08840799376368934\n",
      "  (0, 118246)\t0.03841589117770809\n",
      "  (0, 143062)\t0.20714954814139439\n",
      "  (0, 115221)\t0.027499790755880063\n",
      "  (0, 139807)\t0.09803455212852417\n",
      "  (0, 17115)\t0.08131677900997591\n",
      "  (0, 127651)\t0.14690091354393958\n",
      "  (0, 133283)\t0.028457915264405158\n",
      "  (0, 47191)\t0.05622350928526644\n",
      "  (0, 57464)\t0.05056381815103461\n",
      "  (0, 42753)\t0.050686428097157676\n",
      "  (0, 111303)\t0.07473914825937934\n",
      "  (0, 61367)\t0.07309482483756098\n",
      "  (0, 149894)\t0.04791958827049434\n",
      "  (0, 41463)\t0.09322332721295044\n",
      "  (0, 96735)\t0.3914959486531566\n",
      "  (0, 144631)\t0.06784589005977572\n",
      "  (0, 82781)\t0.05789166559539213\n",
      "  (0, 110774)\t0.05929033756783865\n",
      "  (0, 94282)\t0.0183559496284576\n"
     ]
    }
   ],
   "source": [
    "# Инициализация TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Векторизация текста\n",
    "X_tfidf = vectorizer.fit_transform(imdb_data['review'])\n",
    "\n",
    "# Вывод результатов векторизации\n",
    "print(\"Размер матрицы TF-IDF:\", X_tfidf.shape)\n",
    "print(\"Тип данных матрицы:\", type(X_tfidf))\n",
    "print(\"Просмотр содержимого матрицы в формате (документ, термин): TF-IDF вес\")\n",
    "print(X_tfidf[0])  # Вывод весов для первого документа в наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Компоненты вектора: частоты N-грам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T20:21:16.831368800Z",
     "start_time": "2024-05-02T20:21:07.086334700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы N-грамм: (50000, 2992968)\n",
      "Тип данных матрицы: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Пример содержимого матрицы в формате (документ, термин): частота\n",
      "  (0, 1851922)\t1\n",
      "  (0, 2188847)\t1\n",
      "  (0, 1657450)\t1\n",
      "  (0, 2869929)\t2\n",
      "  (0, 1886544)\t1\n",
      "  (0, 829041)\t1\n",
      "  (0, 2982926)\t1\n",
      "  (0, 1245384)\t1\n",
      "  (0, 2198558)\t1\n",
      "  (0, 863684)\t1\n",
      "  (0, 1176393)\t1\n",
      "  (0, 985138)\t1\n",
      "  (0, 2649134)\t1\n",
      "  (0, 2533134)\t1\n",
      "  (0, 1886508)\t1\n",
      "  (0, 330711)\t1\n",
      "  (0, 2774786)\t1\n",
      "  (0, 2270188)\t1\n",
      "  (0, 2832495)\t1\n",
      "  (0, 2337344)\t1\n",
      "  (0, 2200110)\t1\n",
      "  (0, 2939452)\t1\n",
      "  (0, 1106542)\t1\n",
      "  (0, 2736555)\t1\n",
      "  (0, 2370977)\t1\n",
      "  :\t:\n",
      "  (0, 1078751)\t1\n",
      "  (0, 186317)\t1\n",
      "  (0, 2889121)\t1\n",
      "  (0, 1607120)\t1\n",
      "  (0, 1667558)\t1\n",
      "  (0, 453105)\t1\n",
      "  (0, 1327192)\t1\n",
      "  (0, 2746208)\t1\n",
      "  (0, 2039099)\t1\n",
      "  (0, 269948)\t1\n",
      "  (0, 751345)\t1\n",
      "  (0, 1444865)\t1\n",
      "  (0, 2527756)\t1\n",
      "  (0, 2407711)\t1\n",
      "  (0, 2039209)\t1\n",
      "  (0, 883048)\t1\n",
      "  (0, 1886599)\t1\n",
      "  (0, 1631652)\t1\n",
      "  (0, 228069)\t1\n",
      "  (0, 489508)\t1\n",
      "  (0, 2765174)\t1\n",
      "  (0, 2828351)\t1\n",
      "  (0, 1083065)\t1\n",
      "  (0, 2703864)\t1\n",
      "  (0, 611282)\t1\n"
     ]
    }
   ],
   "source": [
    "# Инициализация CountVectorizer для использования биграмм (2-грамм) и триграмм (3-грамм)\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "# Векторизация текста\n",
    "X_ngrams = vectorizer.fit_transform(imdb_data['review'])\n",
    "\n",
    "# Вывод результатов векторизации\n",
    "print(\"Размер матрицы N-грамм:\", X_ngrams.shape)\n",
    "print(\"Тип данных матрицы:\", type(X_ngrams))\n",
    "print(\"Пример содержимого матрицы в формате (документ, термин): частота\")\n",
    "print(X_ngrams[0])  # Вывод частот для первого документа в наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. Исследование моделей\n",
    "\n",
    "<table>\n",
    "\t\t<tr>\n",
    "\t\t\t<td></td>\n",
    "\t\t\t<td>$y = 1$</td>\n",
    "\t\t\t<td>$y = 0$</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>$a(x) = 1$</td>\n",
    "\t\t\t<td>True Positive (TP)</td>\n",
    "\t\t\t<td>False Positive (FP)</td>\n",
    "\t\t</tr>\n",
    "    \t<tr>\n",
    "\t\t\t<td>$a(x) = 0$</td>\n",
    "\t\t\t<td>False Negative (FN)</td>\n",
    "\t\t\t<td>True Negative (TN)</td>\n",
    "\t\t</tr>\n",
    "</table>\n",
    "\n",
    "В зависимости от способа представления оценить качество классификации как долю правильных ответов на выборке ($\\operatorname{accuracy} = \\frac{\\operatorname{TP} + \\operatorname{TN}}{\\operatorname{TP} + \\operatorname{TN} + \\operatorname{FP} + \\operatorname{FN}}$). Используйте перекрестную проверку ([cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)).\n",
    "\n",
    "Для каждого из нижеперечисленных моделей необходимо определить оптимальные гиперпараметры ([GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html))\n",
    "\n",
    "Качество классификации оцениваем для следующих моделей:\n",
    "\n",
    "#### 1. Машина опорных векторов ([SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T23:22:28.644860800Z",
     "start_time": "2024-05-02T20:21:16.833369500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение с использованием TF-IDF\n",
      "Лучшие параметры для TF-IDF: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Лучшая точность для TF-IDF: 0.8497\n",
      "\n",
      "Обучение с использованием Count Vectors\n",
      "Лучшие параметры для Count Vectors: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Лучшая точность для Count Vectors: 0.84472\n",
      "\n",
      "Обучение с использованием N-grams\n",
      "Лучшие параметры для N-grams: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Лучшая точность для N-grams: 0.72146\n"
     ]
    }
   ],
   "source": [
    "# Инициализация векторизаторов\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "count_vectorizer = CountVectorizer(max_features=500)\n",
    "ngram_vectorizer = CountVectorizer(max_features=500, ngram_range=(2, 2))\n",
    "\n",
    "# Векторизация данных\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(imdb_data['review'])\n",
    "X_counts = count_vectorizer.fit_transform(imdb_data['review'])\n",
    "X_ngrams = ngram_vectorizer.fit_transform(imdb_data['review'])\n",
    "\n",
    "y = imdb_data['sentiment']  # Целевая переменная\n",
    "\n",
    "# Настройка кросс-валидации\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Параметры для GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "\n",
    "# Общая функция для выполнения Grid Search и обучения\n",
    "def train_and_evaluate(X, y, vectorizer_name):\n",
    "    print(f\"Обучение с использованием {vectorizer_name}\")\n",
    "    model = SVC()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print(f\"Лучшие параметры для {vectorizer_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Лучшая точность для {vectorizer_name}: {grid_search.best_score_}\\n\")\n",
    "\n",
    "\n",
    "# Обучение и оценка для каждой векторизации\n",
    "train_and_evaluate(X_tfidf, y, \"TF-IDF\")\n",
    "train_and_evaluate(X_counts, y, \"Count Vectors\")\n",
    "train_and_evaluate(X_ngrams, y, \"N-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Случайный лес ([RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T23:50:18.646376100Z",
     "start_time": "2024-05-02T23:22:28.648905200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели Random Forest с использованием TF-IDF\n",
      "Лучшие параметры для TF-IDF: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Лучшая точность для TF-IDF: 0.8218799999999999\n",
      "\n",
      "Обучение модели Random Forest с использованием Count Vectors\n",
      "Лучшие параметры для Count Vectors: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Лучшая точность для Count Vectors: 0.82\n",
      "\n",
      "Обучение модели Random Forest с использованием N-grams\n",
      "Лучшие параметры для N-grams: {'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 500}\n",
      "Лучшая точность для N-grams: 0.6975\n"
     ]
    }
   ],
   "source": [
    "# Инициализация векторизаторов\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "count_vectorizer = CountVectorizer(max_features=500)\n",
    "ngram_vectorizer = CountVectorizer(max_features=500, ngram_range=(2, 2))\n",
    "\n",
    "# Векторизация данных\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(imdb_data['review'])\n",
    "X_counts = count_vectorizer.fit_transform(imdb_data['review'])\n",
    "X_ngrams = ngram_vectorizer.fit_transform(imdb_data['review'])\n",
    "\n",
    "y = imdb_data['sentiment']  # Целевая переменная\n",
    "\n",
    "# Настройка кросс-валидации\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Параметры для GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Общая функция для выполнения Grid Search и обучения\n",
    "def train_and_evaluate_rf(X, y, vectorizer_name):\n",
    "    print(f\"Обучение модели Random Forest с использованием {vectorizer_name}\")\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search_rf.fit(X, y)\n",
    "    print(f\"Лучшие параметры для {vectorizer_name}: {grid_search_rf.best_params_}\")\n",
    "    print(f\"Лучшая точность для {vectorizer_name}: {grid_search_rf.best_score_}\\n\")\n",
    "\n",
    "\n",
    "# Обучение и оценка для каждой векторизации\n",
    "train_and_evaluate_rf(X_tfidf, y, \"TF-IDF\")\n",
    "train_and_evaluate_rf(X_counts, y, \"Count Vectors\")\n",
    "train_and_evaluate_rf(X_ngrams, y, \"N-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. Сравнение результатов\n",
    "\n",
    "Сравнить точность обученных моделей. Найти наиболее точную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T04:49:33.559200300Z",
     "start_time": "2024-05-03T04:31:11.974223800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC on Count Vectors: 0.8494\n",
      "Accuracy of SVC on TF-IDF: 0.8524\n",
      "Accuracy of SVC on N-grams: 0.7208\n",
      "Accuracy of Random Forest on Count Vectors: 0.8226\n",
      "Accuracy of Random Forest on TF-IDF: 0.8246\n",
      "Accuracy of Random Forest on N-grams: 0.7011\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на обучающие и тестовые выборки для каждого типа данных\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_counts, X_test_counts, y_train_counts, y_test_counts = train_test_split(X_counts, y, test_size=0.2, random_state=42)\n",
    "X_train_ngrams, X_test_ngrams, y_train_ngrams, y_test_ngrams = train_test_split(X_ngrams, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение SVC на Count Vectors\n",
    "svc_counts = SVC(C=10, gamma=0.001, kernel='rbf')\n",
    "svc_counts.fit(X_train_counts, y_train_counts)\n",
    "y_pred_counts_svc = svc_counts.predict(X_test_counts)\n",
    "accuracy_counts_svc = accuracy_score(y_test_counts, y_pred_counts_svc)\n",
    "print(f\"Accuracy of SVC on Count Vectors: {accuracy_counts_svc}\")\n",
    "\n",
    "# Обучение SVC на TF-IDF \n",
    "svc_tfidf = SVC(C=1, gamma='scale', kernel='rbf')\n",
    "svc_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf = svc_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
    "print(f\"Accuracy of SVC on TF-IDF: {accuracy_tfidf}\")\n",
    "\n",
    "# Обучение SVC на N-grams\n",
    "svc_ngrams = SVC(C=1, gamma=0.1, kernel='rbf')\n",
    "svc_ngrams.fit(X_train_ngrams, y_train_ngrams)\n",
    "y_pred_ngrams_svc = svc_ngrams.predict(X_test_ngrams)\n",
    "accuracy_ngrams_svc = accuracy_score(y_test_ngrams, y_pred_ngrams_svc)\n",
    "print(f\"Accuracy of SVC on N-grams: {accuracy_ngrams_svc}\")\n",
    "\n",
    "# Обучение Random Forest на Count Vectors\n",
    "rf_counts = RandomForestClassifier(n_estimators=500, max_features='log2', max_depth=20, min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "rf_counts.fit(X_train_counts, y_train_counts)\n",
    "y_pred_counts = rf_counts.predict(X_test_counts)\n",
    "accuracy_counts = accuracy_score(y_test_counts, y_pred_counts)\n",
    "print(f\"Accuracy of Random Forest on Count Vectors: {accuracy_counts}\")\n",
    "\n",
    "# Обучение Random Forest на TF-IDF\n",
    "rf_tfidf = RandomForestClassifier(n_estimators=500, max_features='log2', max_depth=20, min_samples_split=5, random_state=42, n_jobs=-1)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf_rf = rf_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf_rf = accuracy_score(y_test_tfidf, y_pred_tfidf_rf)\n",
    "print(f\"Accuracy of Random Forest on TF-IDF: {accuracy_tfidf_rf}\")\n",
    "\n",
    "# Обучение Random Forest на N-grams\n",
    "rf_ngrams = RandomForestClassifier(n_estimators=500, max_features='log2', max_depth=20, min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "rf_ngrams.fit(X_train_ngrams, y_train_ngrams)\n",
    "y_pred_ngrams = rf_ngrams.predict(X_test_ngrams)\n",
    "accuracy_ngrams = accuracy_score(y_test_ngrams, y_pred_ngrams)\n",
    "print(f\"Accuracy of Random Forest on N-grams: {accuracy_ngrams}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
